{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize \n",
    "from transformers import BertTokenizer, AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'Sage'\n",
    "model_name = 'epoch_14_model_sage_bert_base_uncased_xtra_label.bin'\n",
    "\n",
    "if platform == 'Azure':\n",
    "    bert_path = '/home/thanish/transformer_models/bert_base_uncased'\n",
    "    test_path = '../test/*'\n",
    "    model_path = '../output/'\n",
    "elif platform == 'Kaggle':\n",
    "    bert_path = '../input/bertlargeuncasedpytorch'\n",
    "    test_path = '/kaggle/input/coleridgeinitiative-show-us-the-data/test/*'\n",
    "    model_path = '../input/coleridgemodels/'\n",
    "else:\n",
    "    bert_path = 'C:/Users/thanisb/Documents/transformer_models/bert_base_uncased/'\n",
    "    test_path = '../test/*'\n",
    "    model_path = '../output/'\n",
    "    \n",
    "config = {'MAX_LEN':512,\n",
    "          'tokenizer': AutoTokenizer.from_pretrained('bert-base-uncased' , do_lower_case=True),\n",
    "          'batch_size':20,\n",
    "          'Epoch': 3,\n",
    "          'test_path':test_path, \n",
    "          'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "          'model_path':model_path,\n",
    "          'model_name':model_name\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_joining(data_dict_id):\n",
    "    '''\n",
    "    This function is to join all the text data from different sections in the json to a single\n",
    "    text file. \n",
    "    '''\n",
    "    data_length = len(data_dict_id)\n",
    "\n",
    "    #     temp = [clean_text(data_dict_id[i]['text']) for i in range(data_length)]\n",
    "    temp = [data_dict_id[i]['text'] for i in range(data_length)]\n",
    "    temp = '. '.join(temp)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_json(test_data_folder):\n",
    "    '''\n",
    "    This function reads all the json input files and return a dictionary containing the id as the key\n",
    "    and all the contents of the json as values\n",
    "    '''\n",
    "\n",
    "    test_text_data = {}\n",
    "    total_files = len(glob.glob(test_data_folder))\n",
    "    \n",
    "    for i, test_json_loc in enumerate(glob.glob(test_data_folder)):\n",
    "        filename = test_json_loc.split(\"/\")[-1][:-5]\n",
    "\n",
    "        with open(test_json_loc, 'r') as f:\n",
    "            test_text_data[filename] = json.load(f)\n",
    "\n",
    "        if (i%1000) == 0:\n",
    "            print(f\"Completed {i}/{total_files}\")\n",
    "\n",
    "    print(\"All files read\")\n",
    "    return test_text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0/4\n",
      "All files read\n"
     ]
    }
   ],
   "source": [
    "test_data_dict = read_test_json(test_data_folder=\"../test/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3f316b38-1a24-45a9-8d8c-4e05a42257c6\n",
      "2f392438-e215-4169-bebf-21ac4ff253e1\n",
      "8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60\n",
      "2100032a-7c33-4bff-97ef-690822c43466\n"
     ]
    }
   ],
   "source": [
    "for i in test_data_dict.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the saved model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model checkpoint: ../output/epoch_14_model_sage_bert_base_uncased_xtra_label.bin\n",
      "Checkpoint loaded\n",
      "Model loaded with all keys matching with the checkpoint\n"
     ]
    }
   ],
   "source": [
    "# initializing the model\n",
    "model = transformers.BertForTokenClassification.from_pretrained('bert-base-uncased',  num_labels = 3)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "# Reading the trained checkpoint model\n",
    "trained_model_name = config['model_path'] + config['model_name']\n",
    "print(\"Trained model checkpoint:\", trained_model_name)\n",
    "checkpoint = torch.load(trained_model_name, map_location = config['device'])\n",
    "print(\"Checkpoint loaded\")\n",
    "\n",
    "# Matching the trained checkpoint model to the initialized model\n",
    "model.load_state_dict(checkpoint)\n",
    "print(\"Model loaded with all keys matching with the checkpoint\")\n",
    "\n",
    "model = model.to(config['device'])\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "def prediction_fn(tokenized_sub_sentence):\n",
    "\n",
    "    tkns = tokenized_sub_sentence\n",
    "    indexed_tokens = config['tokenizer'].convert_tokens_to_ids(tkns)\n",
    "    segments_ids = [0] * len(indexed_tokens)\n",
    "\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(config['device'])\n",
    "    segments_tensors = torch.tensor([segments_ids]).to(config['device'])\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logit = model(tokens_tensor, \n",
    "                      token_type_ids=None,\n",
    "                      attention_mask=segments_tensors)\n",
    "\n",
    "        logit_new = logit[0].argmax(2).detach().cpu().numpy().tolist()\n",
    "        prediction = logit_new[0]\n",
    "\n",
    "#         print(tkns)\n",
    "#         print(logit_new)\n",
    "#         print(prediction)\n",
    "        \n",
    "        kword = ''\n",
    "        kword_list = []\n",
    "\n",
    "        for k, j in enumerate(prediction):\n",
    "            if (len(prediction)>1):\n",
    "\n",
    "                if (j!=0) & (k==0):\n",
    "                    #if it's the first word in the first position\n",
    "                    #print('At begin first word')\n",
    "                    begin = tkns[k]\n",
    "                    kword = begin\n",
    "\n",
    "                elif (j!=0) & (k>=1) & (prediction[k-1]==0):\n",
    "                    #begin word is in the middle of the sentence\n",
    "                    begin = tkns[k]\n",
    "                    previous = tkns[k-1]\n",
    "\n",
    "                    if begin.startswith('##'):\n",
    "                        kword = previous + begin[2:]\n",
    "                    else:\n",
    "                        kword = begin\n",
    "\n",
    "                    if k == (len(prediction) - 1):\n",
    "                        #print('begin and end word is the last word of the sentence')\n",
    "                        kword_list.append(kword.rstrip().lstrip())\n",
    "\n",
    "                elif (j!=0) & (k>=1) & (prediction[k-1]!=0):\n",
    "                    # intermediate word of the same keyword\n",
    "                    inter = tkns[k]\n",
    "\n",
    "                    if inter.startswith('##'):\n",
    "                        kword = kword + \"\" + inter[2:]\n",
    "                    else:\n",
    "                        kword = kword + \" \" + inter\n",
    "\n",
    "\n",
    "                    if k == (len(prediction) - 1):\n",
    "                        #print('begin and end')\n",
    "                        kword_list.append(kword.rstrip().lstrip())\n",
    "\n",
    "                elif (j==0) & (k>=1) & (prediction[k-1] !=0):\n",
    "                    # End of a keywords but not end of sentence.\n",
    "                    kword_list.append(kword.rstrip().lstrip())\n",
    "                    kword = ''\n",
    "                    inter = ''\n",
    "            else:\n",
    "                if (j!=0):\n",
    "                    begin = tkns[k]\n",
    "                    kword = begin\n",
    "                    kword_list.append(kword.rstrip().lstrip())\n",
    "#         print(kword_list)\n",
    "#         print(\"\")\n",
    "    return kword_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_sent_split(text):\n",
    "    sent_split = text.split(\" \")\n",
    "\n",
    "    start = 0\n",
    "    end = len(sent_split)\n",
    "    max_length = 64\n",
    "\n",
    "    final_sent_split = []\n",
    "    for i in range(start, end, max_length):\n",
    "        temp = sent_split[i: (i + max_length)]\n",
    "        final_sent_split.append(\" \".join(i for i in temp))\n",
    "    return final_sent_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data_dict):\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    for i, Id in enumerate(data_dict.keys()):\n",
    "        current_id_predictions = []\n",
    "        \n",
    "        print(Id)\n",
    "        sentences = data_joining(data_dict[Id])\n",
    "        sentence_tokens = sent_tokenize(sentences)\n",
    "        \n",
    "        for sub_sentence in sentence_tokens:\n",
    "            cleaned_sub_sentence = clean_text(sub_sentence)\n",
    "        \n",
    "            # Tokenize the sentence\n",
    "            tokenized_sub_sentence = config['tokenizer'].tokenize(cleaned_sub_sentence)\n",
    "            \n",
    "            if len(tokenized_sub_sentence) == 0:\n",
    "                # If the tokenized sentence are empty\n",
    "                sub_sentence_prediction_kword_list = []\n",
    "                \n",
    "            elif len(tokenized_sub_sentence) <= 512:\n",
    "                # If the tokenized sentence are less than 512\n",
    "                sub_sentence_prediction_kword_list = prediction_fn(tokenized_sub_sentence)\n",
    "\n",
    "            else:\n",
    "                # If the tokenized sentence are >512 which is long sentences\n",
    "                long_sent_kword_list = []\n",
    "                \n",
    "                tokenized_sub_sentence_tok_split = long_sent_split(text = tokenized_sub_sentence)\n",
    "                for i, sent_tok in enumerate(tokenized_sub_sentence_tok_split):\n",
    "                    if len(sent) != 0:\n",
    "                        kword_list = prediction_fn(sent_tok)\n",
    "                        long_sent_kword_list.append(kword_list)\n",
    "                flat_long_sent_kword = [item for sublist in long_sent_kword_list for item in sublist]\n",
    "                sub_sentence_prediction_kword_list = flat_long_sent_kword\n",
    "                            \n",
    "            if len(sub_sentence_prediction_kword_list) !=0:\n",
    "                current_id_predictions = current_id_predictions + sub_sentence_prediction_kword_list\n",
    "\n",
    "        results[Id] = list(set(current_id_predictions))\n",
    "                \n",
    "    print(\"All predictions completed\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results_1 = get_predictions(data_dict = test_data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_few_word_prediction(prediction_dict):\n",
    "    final_result = {}\n",
    "    for ID in prediction_dict.keys():\n",
    "        temp = []\n",
    "\n",
    "        for pred in prediction_dict[ID]:\n",
    "            pred_split = pred.split(\" \")\n",
    "            condition1 = len(pred_split)<=2\n",
    "            condition2 = 'adni' not in pred\n",
    "            condition3 = 'cccsl' not in pred\n",
    "            condition4 = 'ibtracs' not in pred\n",
    "            condition5 = 'slosh model' not in pred\n",
    "            \n",
    "            if condition1 & condition2 & condition3 & condition4 & condition5:\n",
    "                pass\n",
    "            else:\n",
    "                temp.append(pred)\n",
    "        final_result[ID] = temp\n",
    "        \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "48\n",
      "19\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'3f316b38-1a24-45a9-8d8c-4e05a42257c6': ['hurricane preparedness and safety',\n",
       "  'island life saving site',\n",
       "  'north carolina emergency management spatial data download portal',\n",
       "  'lidar elevation data sets',\n",
       "  'nc floodplain mapping',\n",
       "  'beach nourishment projects',\n",
       "  'jersey beach profile network',\n",
       "  'storm surge inundation mapping',\n",
       "  'coastal observation station',\n",
       "  'beach monitoring program',\n",
       "  'ground water tables',\n",
       "  'human natural system',\n",
       "  'nc flood risk information system',\n",
       "  'nags head fire station',\n",
       "  'usgs coastal vulnerability index',\n",
       "  'coastal resources commission',\n",
       "  'coastal flood risk study',\n",
       "  'historic resource assets',\n",
       "  'sea level rise scenarios',\n",
       "  'sea level rise risk management study',\n",
       "  'sea lake and overland surges from hurricanes',\n",
       "  'strategic site selection',\n",
       "  'coastal change hazards portal',\n",
       "  'a nourishment project',\n",
       "  'national environmental policy act',\n",
       "  'airborne elevation data',\n",
       "  'shoreline change rates',\n",
       "  'hazard mitigation planning',\n",
       "  'flood insurance rate',\n",
       "  'shoreline analysis system',\n",
       "  'beach nourishment project',\n",
       "  'hatteras national seashore',\n",
       "  'beach nourishment fund',\n",
       "  'shoreline change rate',\n",
       "  'natural neighbor interpolation',\n",
       "  'reporting output and structure',\n",
       "  'coastal erosion study',\n",
       "  'surges and structures',\n",
       "  'shoreline change assessment',\n",
       "  'community vulnerability assessment',\n",
       "  'coastal salinity database',\n",
       "  'usgs dsas 6',\n",
       "  'nc floodplain mapping program',\n",
       "  'floodplain mapping program',\n",
       "  'coastal management policy',\n",
       "  'nps parks and facilities',\n",
       "  'island historic district',\n",
       "  'slosh model'],\n",
       " '2f392438-e215-4169-bebf-21ac4ff253e1': ['international data base',\n",
       "  'international performance benchmarks',\n",
       "  'international education projects',\n",
       "  'advanced research programs',\n",
       "  'consumer price indices',\n",
       "  'international standard classification of occupations',\n",
       "  'international education data',\n",
       "  'national purchasing power parities',\n",
       "  'general certificate of',\n",
       "  'progress in international reading literacy study',\n",
       "  'population and enrollment data',\n",
       "  'these programs of study',\n",
       "  'national salary schedules',\n",
       "  'remedial reading specialist',\n",
       "  '2 reference year',\n",
       "  'program for international student assessment',\n",
       "  'national purchasing power par',\n",
       "  'school achievement data',\n",
       "  'current population survey',\n",
       "  'population in the united states',\n",
       "  'education expenditure data',\n",
       "  'international standard classification of',\n",
       "  '##medial reading specialist',\n",
       "  'integrated postsecondary education data system',\n",
       "  'instructional resource allocation',\n",
       "  'vocational higher education',\n",
       "  'secondary education employment',\n",
       "  'trends in international mathematics and science study',\n",
       "  'national education systems',\n",
       "  'science literacy scale',\n",
       "  'earth life and physical sciences',\n",
       "  'country 2006 rounds',\n",
       "  '1 postsecondary nontertiary data',\n",
       "  'general certificate of secondary education qualifications',\n",
       "  'certificates of higher education',\n",
       "  'schools and staffing survey',\n",
       "  'academic higher education',\n",
       "  'united states reports',\n",
       "  'national education data',\n",
       "  'postgraduate certificate of education',\n",
       "  'country reporting data',\n",
       "  'organization for economic cooperation and development o',\n",
       "  'school principals reports',\n",
       "  'programs of study',\n",
       "  'general certificate of education',\n",
       "  'national financial reports',\n",
       "  'digest of education statistics',\n",
       "  'international standard classification of education'],\n",
       " '8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60': ['food marketing institute',\n",
       "  'national dataset foodaps',\n",
       "  'bureau of labor statistics',\n",
       "  'consumer expenditure survey',\n",
       "  'food expenditure shares',\n",
       "  'food purchasing habits',\n",
       "  'party access agreement',\n",
       "  'food access research atlas',\n",
       "  'food at home purchases',\n",
       "  'market basket items',\n",
       "  'primary food shopper',\n",
       "  'secondary food stores',\n",
       "  'fruits and vegetables',\n",
       "  'food access problems',\n",
       "  'community food security',\n",
       "  'food shopping patterns',\n",
       "  'rural urban continuum codes',\n",
       "  'we eat in america',\n",
       "  'fruit and vegetable consumption'],\n",
       " '2100032a-7c33-4bff-97ef-690822c43466': ['alzheimer s disease neuroimaging initiative adni',\n",
       "  'framingham heart study',\n",
       "  'birth cohort study',\n",
       "  'heart and aging research',\n",
       "  'cardiovascular health study']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch 0\n",
    "res = remove_few_word_prediction(prediction_dict=results_1)\n",
    "for i in res.keys():\n",
    "    print(len(res[i]))\n",
    "    \n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
