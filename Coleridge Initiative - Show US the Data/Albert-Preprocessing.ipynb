{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize \n",
    "from transformers import BertTokenizer, AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "import datetime \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'Azure'\n",
    "model_name = 'model_sage_albert_base.bin'\n",
    "\n",
    "if platform == 'Azure':\n",
    "    bert_path = '/home/thanish/transformer_models/bert_large_uncased'\n",
    "    test_path = '../test/*'\n",
    "    model_path = '../output/'\n",
    "elif platform == 'Kaggle':\n",
    "    bert_path = '../input/bertlargeuncasedpytorch'\n",
    "    test_path = '/kaggle/input/coleridgeinitiative-show-us-the-data/test/*'\n",
    "    model_path = '../input/coleridgemodels/'\n",
    "else:\n",
    "    bert_path = 'C:/Users/thanisb/Documents/transformer_models/bert_large_uncased/'\n",
    "    test_path = '../test/*'\n",
    "    model_path = '../output/'\n",
    "    \n",
    "config = {'MAX_LEN':128,\n",
    "          'tokenizer': AutoTokenizer.from_pretrained('albert-base-v2' , do_lower_case=True),\n",
    "          'batch_size':16,\n",
    "          'Epoch': 15,\n",
    "          'test_path':test_path, \n",
    "          'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "          'model_path':model_path,\n",
    "          'model_name':model_name\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the train csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>pub_title</th>\n",
       "      <th>dataset_title</th>\n",
       "      <th>dataset_label</th>\n",
       "      <th>cleaned_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d0fa7568-7d8e-4db9-870f-f9c6f668c17b</td>\n",
       "      <td>The Impact of Dual Enrollment on College Degre...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f26f645-3dec-485d-b68d-f013c9e05e60</td>\n",
       "      <td>Educational Attainment of High School Dropouts...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c5d5cd2c-59de-4f29-bbb1-6a88c7b52f29</td>\n",
       "      <td>Differences in Outcomes for Female and Male St...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5c9a3bc9-41ba-4574-ad71-e25c1442c8af</td>\n",
       "      <td>Stepping Stone and Option Value in a Model of ...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c754dec7-c5a3-4337-9892-c02158475064</td>\n",
       "      <td>Parental Effort, School Resources, and Student...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19656</th>\n",
       "      <td>b3498176-8832-4033-aea6-b5ea85ea04c4</td>\n",
       "      <td>RSNA International Trends: A Global Perspectiv...</td>\n",
       "      <td>RSNA International COVID-19 Open Radiology Dat...</td>\n",
       "      <td>RSNA International COVID Open Radiology Database</td>\n",
       "      <td>rsna international covid open radiology database</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19657</th>\n",
       "      <td>f77eb51f-c3ac-420b-9586-cb187849c321</td>\n",
       "      <td>MCCS: a novel recognition pattern-based method...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19658</th>\n",
       "      <td>ab59bcdd-7b7c-4107-93f5-0ccaf749236c</td>\n",
       "      <td>Quantitative Structure–Activity Relationship M...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19659</th>\n",
       "      <td>fd23e7e0-a5d2-4f98-992d-9209c85153bb</td>\n",
       "      <td>A ligand-based computational drug repurposing ...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>fd23e7e0-a5d2-4f98-992d-9209c85153bb</td>\n",
       "      <td>A ligand-based computational drug repurposing ...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds data</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19661 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Id  \\\n",
       "0      d0fa7568-7d8e-4db9-870f-f9c6f668c17b   \n",
       "1      2f26f645-3dec-485d-b68d-f013c9e05e60   \n",
       "2      c5d5cd2c-59de-4f29-bbb1-6a88c7b52f29   \n",
       "3      5c9a3bc9-41ba-4574-ad71-e25c1442c8af   \n",
       "4      c754dec7-c5a3-4337-9892-c02158475064   \n",
       "...                                     ...   \n",
       "19656  b3498176-8832-4033-aea6-b5ea85ea04c4   \n",
       "19657  f77eb51f-c3ac-420b-9586-cb187849c321   \n",
       "19658  ab59bcdd-7b7c-4107-93f5-0ccaf749236c   \n",
       "19659  fd23e7e0-a5d2-4f98-992d-9209c85153bb   \n",
       "19660  fd23e7e0-a5d2-4f98-992d-9209c85153bb   \n",
       "\n",
       "                                               pub_title  \\\n",
       "0      The Impact of Dual Enrollment on College Degre...   \n",
       "1      Educational Attainment of High School Dropouts...   \n",
       "2      Differences in Outcomes for Female and Male St...   \n",
       "3      Stepping Stone and Option Value in a Model of ...   \n",
       "4      Parental Effort, School Resources, and Student...   \n",
       "...                                                  ...   \n",
       "19656  RSNA International Trends: A Global Perspectiv...   \n",
       "19657  MCCS: a novel recognition pattern-based method...   \n",
       "19658  Quantitative Structure–Activity Relationship M...   \n",
       "19659  A ligand-based computational drug repurposing ...   \n",
       "19660  A ligand-based computational drug repurposing ...   \n",
       "\n",
       "                                           dataset_title  \\\n",
       "0                  National Education Longitudinal Study   \n",
       "1                  National Education Longitudinal Study   \n",
       "2                  National Education Longitudinal Study   \n",
       "3                  National Education Longitudinal Study   \n",
       "4                  National Education Longitudinal Study   \n",
       "...                                                  ...   \n",
       "19656  RSNA International COVID-19 Open Radiology Dat...   \n",
       "19657  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19658  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19659  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19660  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "\n",
       "                                           dataset_label  \\\n",
       "0                  National Education Longitudinal Study   \n",
       "1                  National Education Longitudinal Study   \n",
       "2                  National Education Longitudinal Study   \n",
       "3                  National Education Longitudinal Study   \n",
       "4                  National Education Longitudinal Study   \n",
       "...                                                  ...   \n",
       "19656   RSNA International COVID Open Radiology Database   \n",
       "19657  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19658  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19659  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19660    CAS COVID-19 antiviral candidate compounds data   \n",
       "\n",
       "                                           cleaned_label  \n",
       "0                  national education longitudinal study  \n",
       "1                  national education longitudinal study  \n",
       "2                  national education longitudinal study  \n",
       "3                  national education longitudinal study  \n",
       "4                  national education longitudinal study  \n",
       "...                                                  ...  \n",
       "19656   rsna international covid open radiology database  \n",
       "19657  cas covid 19 antiviral candidate compounds dat...  \n",
       "19658  cas covid 19 antiviral candidate compounds dat...  \n",
       "19659  cas covid 19 antiviral candidate compounds dat...  \n",
       "19660    cas covid 19 antiviral candidate compounds data  \n",
       "\n",
       "[19661 rows x 5 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../train.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining the labels together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>label_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007f880-0a9b-492d-9a58-76eb0b0e0bd7</td>\n",
       "      <td>1</td>\n",
       "      <td>program for the international assessment of ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008656f-0ba2-4632-8602-3017b44c2e90</td>\n",
       "      <td>1</td>\n",
       "      <td>trends in international mathematics and scienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n",
       "      <td>1</td>\n",
       "      <td>agricultural resources management survey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n",
       "      <td>2</td>\n",
       "      <td>adni|alzheimer s disease neuroimaging initiati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0010357a-6365-4e5f-b982-582e6d32c3ee</td>\n",
       "      <td>1</td>\n",
       "      <td>genome sequence of covid 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14311</th>\n",
       "      <td>ffd19b3c-f941-45e5-9382-934b5041ec96</td>\n",
       "      <td>1</td>\n",
       "      <td>census of agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14312</th>\n",
       "      <td>ffd4d86a-0f26-44cc-baed-f0e209cc22af</td>\n",
       "      <td>1</td>\n",
       "      <td>alzheimer s disease neuroimaging initiative adni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14313</th>\n",
       "      <td>ffe7f334-245a-4de7-b600-d7ff4e28bfca</td>\n",
       "      <td>1</td>\n",
       "      <td>genome sequences of sars cov 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14314</th>\n",
       "      <td>ffeb3568-7aed-4dbe-b177-cbd7f46f34af</td>\n",
       "      <td>1</td>\n",
       "      <td>trends in international mathematics and scienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14315</th>\n",
       "      <td>ffee2676-a778-4521-b947-e1e420b126c5</td>\n",
       "      <td>2</td>\n",
       "      <td>beginning postsecondary student|beginning post...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14316 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Id  label_count  \\\n",
       "0      0007f880-0a9b-492d-9a58-76eb0b0e0bd7            1   \n",
       "1      0008656f-0ba2-4632-8602-3017b44c2e90            1   \n",
       "2      000e04d6-d6ef-442f-b070-4309493221ba            1   \n",
       "3      000efc17-13d8-433d-8f62-a3932fe4f3b8            2   \n",
       "4      0010357a-6365-4e5f-b982-582e6d32c3ee            1   \n",
       "...                                     ...          ...   \n",
       "14311  ffd19b3c-f941-45e5-9382-934b5041ec96            1   \n",
       "14312  ffd4d86a-0f26-44cc-baed-f0e209cc22af            1   \n",
       "14313  ffe7f334-245a-4de7-b600-d7ff4e28bfca            1   \n",
       "14314  ffeb3568-7aed-4dbe-b177-cbd7f46f34af            1   \n",
       "14315  ffee2676-a778-4521-b947-e1e420b126c5            2   \n",
       "\n",
       "                                                   label  \n",
       "0      program for the international assessment of ad...  \n",
       "1      trends in international mathematics and scienc...  \n",
       "2               agricultural resources management survey  \n",
       "3      adni|alzheimer s disease neuroimaging initiati...  \n",
       "4                            genome sequence of covid 19  \n",
       "...                                                  ...  \n",
       "14311                              census of agriculture  \n",
       "14312  alzheimer s disease neuroimaging initiative adni   \n",
       "14313                     genome sequences of sars cov 2  \n",
       "14314  trends in international mathematics and scienc...  \n",
       "14315  beginning postsecondary student|beginning post...  \n",
       "\n",
       "[14316 rows x 3 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train.groupby(['Id']).agg(label_count = ('cleaned_label', 'count'),\n",
    "                                     label = ('cleaned_label', '|'.join)).reset_index()\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading all the json train files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_json(df):\n",
    "    '''\n",
    "    This function reads all the json input files and return a dictionary containing the id as the key\n",
    "    and all the contents of the json as values\n",
    "    '''\n",
    "    text_data = {}\n",
    "    for i, rec_id in tqdm(enumerate(df.Id), total = len(df.Id)):\n",
    "        location = f'../train/{rec_id}.json'\n",
    "\n",
    "        with open(location, 'r') as f:\n",
    "            text_data[rec_id] = json.load(f)\n",
    "        \n",
    "    print(\"All files read\")\n",
    "    end = datetime.datetime.now()\n",
    "    \n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 12/14316 [00:00<02:05, 113.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.95 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 14316/14316 [00:36<00:00, 389.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files read\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "data_dict = read_all_json(df=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_joining(data_dict_id):\n",
    "    '''\n",
    "    This function is to join all the text data from different sections in the json to a single\n",
    "    text file. \n",
    "    '''\n",
    "    data_length = len(data_dict_id)\n",
    "\n",
    "    #     temp = [clean_text(data_dict_id[i]['text']) for i in range(data_length)]\n",
    "    temp = [data_dict_id[i]['text'] for i in range(data_length)]\n",
    "    temp = '. '.join(temp)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the extra label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 1)\n",
      "Remove <3 words labels\n",
      "(167, 2)\n",
      "Remove Train labels\n",
      "(167,)\n",
      "167\n"
     ]
    }
   ],
   "source": [
    "uniq_train_label = train.cleaned_label.str.strip().unique()\n",
    "\n",
    "extra_label_type='cleaned_extra_label'\n",
    "\n",
    "if extra_label_type == 'raw':\n",
    "    extra_label_800 = pd.read_csv(\"../extra_data/data_set_800.csv\")\n",
    "    extra_label_26897 = pd.read_csv(\"../extra_data/data_set_26897.csv\")\n",
    "\n",
    "    print(extra_label_800.shape)\n",
    "    print(extra_label_26897.shape)\n",
    "\n",
    "    extra_label_final = extra_label_800\n",
    "    extra_label_final = pd.concat([extra_label_800, extra_label_26897]).reset_index(drop=True)\n",
    "    print(extra_label_final.shape)\n",
    "\n",
    "    extra_label_final.title = extra_label_final.title.apply(lambda x: clean_text(x))\n",
    "\n",
    "    # Remove one word labels\n",
    "    print(\"Remove all <2 word labels\")\n",
    "    extra_label_final['label_len'] = extra_label_final.title.apply(lambda x : len(x.split(\" \")))\n",
    "    extra_label_final = extra_label_final[extra_label_final.label_len>=3].reset_index(drop=True)\n",
    "    extra_label_final\n",
    "    print(extra_label_final.shape)\n",
    "\n",
    "    # Removing the train label\n",
    "    print(\"Remove train labels\")\n",
    "    unique_extra_label_final = np.setdiff1d(extra_label_final.title, uniq_train_label)\n",
    "    print(unique_extra_label_final.shape)\n",
    "\n",
    "    unique_extra_label_final = unique_extra_label_final.tolist()\n",
    "    print(len(unique_extra_label_final))\n",
    "    \n",
    "elif extra_label_type == 'cleaned_extra_label':\n",
    "    cleaned_extra_label_df = pd.read_csv(\"../extra_data/cleaned_extra_labels.csv\")\n",
    "    print(cleaned_extra_label_df.shape)\n",
    "\n",
    "    cleaned_extra_label_df.Cleaned_extra_label = cleaned_extra_label_df.Cleaned_extra_label.apply(lambda x: clean_text(x))\n",
    "\n",
    "    # Remove one word labels\n",
    "    print(\"Remove <3 words labels\")\n",
    "    cleaned_extra_label_df['label_len'] = cleaned_extra_label_df.Cleaned_extra_label.apply(lambda x : len(x.split(\" \")))\n",
    "    cleaned_extra_label_df = cleaned_extra_label_df[cleaned_extra_label_df.label_len>=3].reset_index(drop=True)\n",
    "    print(cleaned_extra_label_df.shape)\n",
    "\n",
    "    # Removing the train label\n",
    "    print(\"Remove Train labels\")\n",
    "    unique_extra_label_final = np.setdiff1d(cleaned_extra_label_df.Cleaned_extra_label, uniq_train_label)\n",
    "    print(unique_extra_label_final.shape)\n",
    "\n",
    "    unique_extra_label_final = unique_extra_label_final.tolist()\n",
    "    print(len(unique_extra_label_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_shorter_sentence(sentence):\n",
    "    sent_tokenized = sent_tokenize(sentence)\n",
    "    \n",
    "    max_length = config['MAX_LEN']\n",
    "    overlap = 20\n",
    "    \n",
    "    final_sentences = []\n",
    "    \n",
    "    for tokenized_sent in sent_tokenized:\n",
    "        sent_tokenized_clean = clean_text(tokenized_sent)\n",
    "        sent_tokenized_clean = sent_tokenized_clean.replace('.','').rstrip() \n",
    "        \n",
    "        tok_sent = sent_tokenized_clean.split(\" \")\n",
    "        \n",
    "        if len(tok_sent)<max_length:\n",
    "            final_sentences.append(sent_tokenized_clean)\n",
    "        else :\n",
    "#             print(\"Making shorter sentences\")\n",
    "            start = 0\n",
    "            end = len(tok_sent)\n",
    "            \n",
    "            for i in range(start, end, max_length-overlap):\n",
    "                temp = tok_sent[i: (i + max_length)]\n",
    "                final_sentences.append(\" \".join(i for i in temp))\n",
    "\n",
    "    return final_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the original sentence\n",
    "\n",
    "def form_labels(sentence, labels_list, extra_label_list):\n",
    "    '''\n",
    "    This function labels the training data \n",
    "    '''\n",
    "    matched_kwords = []\n",
    "    matched_token = []\n",
    "    un_matched_kwords = []\n",
    "    label = []\n",
    "\n",
    "    # Since there are many sentences which are more than 512. Let's make the max length of all\n",
    "    # the sentences be 64\n",
    "    tokens = make_shorter_sentence(sentence)\n",
    "    \n",
    "    for tok in tokens:    \n",
    "        tok_split = config['tokenizer'].tokenize(tok)\n",
    "        \n",
    "        z = np.array(['O'] * len(tok_split)) # Create final label == len(tokens) of each sentence\n",
    "        matched_keywords = 0 # Initially no kword matched    \n",
    "\n",
    "        for kword in labels_list:\n",
    "            if kword in tok: #This is to first check if the keyword is in the text and then go ahead\n",
    "                kword_split = config['tokenizer'].tokenize(kword)\n",
    "                for i in range(len(tok_split)):\n",
    "                    if tok_split[i: (i + len(kword_split))] == kword_split:\n",
    "                        matched_keywords += 1\n",
    "    #                     print(\"matched keyword with token:\", tok_split[i: (i+len(kword_split))] )\n",
    "    #                     print(tok_split)\n",
    "\n",
    "                        if (len(kword_split) == 1):\n",
    "                            z[i] = 'B'\n",
    "                        else:\n",
    "                            z[i] = 'B'\n",
    "                            z[(i+1) : (i+ len(kword_split))]= 'B'\n",
    "\n",
    "                        if matched_keywords >1:\n",
    "                            label[-1] = (z.tolist())\n",
    "                            matched_token[-1] = tok\n",
    "                            matched_kwords[-1].append(kword)\n",
    "                        else:\n",
    "                            label.append(z.tolist())\n",
    "                            matched_token.append(tok)\n",
    "                            matched_kwords.append([kword])\n",
    "                        #print(label[-1])\n",
    "                        #print(\"\")\n",
    "        #                 break\n",
    "                    else:\n",
    "                        un_matched_kwords.append(tok)\n",
    "                \n",
    "    return matched_token, matched_kwords, label, un_matched_kwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def labelling(dataset, data_dict):\n",
    "    \n",
    "    Id_list_ = []\n",
    "    sentences_ = []\n",
    "    key_ = []\n",
    "    labels_ = []\n",
    "    un_mat = []\n",
    "    un_matched_reviews = 0\n",
    "\n",
    "    for i, Id in tqdm(enumerate(dataset.Id), total=len(dataset.Id)):\n",
    "        print(Id)\n",
    "        \n",
    "        sentence = data_joining(data_dict[Id])\n",
    "        labels = train_df.label[train_df.Id == Id].tolist()[0].split(\"|\")\n",
    "\n",
    "        s, k, l, un_matched = form_labels(sentence=sentence, \n",
    "                                          labels_list = labels, \n",
    "                                          extra_label_list=unique_extra_label_final)\n",
    "\n",
    "        if len(s) == 0:\n",
    "            un_matched_reviews += 1\n",
    "            un_mat.append(un_matched)\n",
    "        else: \n",
    "            sentences_.append(s)\n",
    "            key_.append(k)\n",
    "            labels_.append(l)\n",
    "            Id_list_.append([Id]*len(l))\n",
    "\n",
    "        if (i%100) == 0:\n",
    "            print(f\"Completed {i}/{train_df.Id.shape[0]}\")\n",
    "\n",
    "    print(\"Total unmatched keywords:\", un_matched_reviews)\n",
    "    sentences = [item for sublist in sentences_ for item in sublist]\n",
    "    final_labels = [item for sublist in labels_ for item in sublist]\n",
    "    keywords = [item for sublist in key_ for item in sublist]\n",
    "    Id_list = [item for sublist in Id_list_ for item in sublist]\n",
    "    \n",
    "    return sentences, final_labels, keywords, Id_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_sentences, train_labels, train_keywords, train_Id_list = labelling(dataset = train_df, data_dict=data_dict)\n",
    "valid_sentences, valid_labels, valid_keywords, valid_Id_list = labelling(dataset = DF_valid)\n",
    "\n",
    "print(\"\")\n",
    "print(f\" train sentences: {len(train_sentences)}, train label: {len(train_labels)}, train keywords: {len(train_keywords)}, train_id list: {len(train_Id_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataFrame to remove the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58678, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>train_sentences</th>\n",
       "      <th>kword</th>\n",
       "      <th>label</th>\n",
       "      <th>sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007f880-0a9b-492d-9a58-76eb0b0e0bd7</td>\n",
       "      <td>in fact organizations are now identifying digi...</td>\n",
       "      <td>['program for the international assessment of ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008656f-0ba2-4632-8602-3017b44c2e90</td>\n",
       "      <td>besides not enough young people are entering s...</td>\n",
       "      <td>['trends in international mathematics and scie...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n",
       "      <td>1 manages access to results of the agricultura...</td>\n",
       "      <td>['agricultural resources management survey']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n",
       "      <td>the agricultural resources management survey a...</td>\n",
       "      <td>['agricultural resources management survey']</td>\n",
       "      <td>['O', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n",
       "      <td>the resulting statistics provide the fulcrum f...</td>\n",
       "      <td>['farm income and wealth statistics']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n",
       "      <td>example atlas of rural and small town america ...</td>\n",
       "      <td>['atlas of rural and small town america', 'cou...</td>\n",
       "      <td>['O', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'O', ...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n",
       "      <td>genetic and neuroimaging data on a sub sample ...</td>\n",
       "      <td>['adni', 'alzheimer s disease neuroimaging ini...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n",
       "      <td>this study used data from the nacc and adni da...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n",
       "      <td>patient recruitment neuroimaging acquisition a...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n",
       "      <td>the adni data set is from a multicenter longit...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n",
       "      <td>neither other scans nor snps were assessed fro...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n",
       "      <td>54 neuroimaging and genetic parameters in adni...</td>\n",
       "      <td>['adni', 'adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', ...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n",
       "      <td>47 55 arterial spin labeling asl images were o...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n",
       "      <td>snp rs704180 in abcc9 and apoe e4 status infor...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n",
       "      <td>this was performed by measuring cbf in conveni...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n",
       "      <td>despite the challenges inherent to a retrospec...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0010357a-6365-4e5f-b982-582e6d32c3ee</td>\n",
       "      <td>the whole genome sequence of covid 19 has abou...</td>\n",
       "      <td>['genome sequence of covid 19']</td>\n",
       "      <td>['O', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'O', ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>002203f0-1c57-4400-abc1-b783c4085743</td>\n",
       "      <td>this work was supported in part by the natural...</td>\n",
       "      <td>['adni', 'alzheimer s disease neuroimaging ini...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>002203f0-1c57-4400-abc1-b783c4085743</td>\n",
       "      <td>as such investigators within adni contributed ...</td>\n",
       "      <td>['adni', 'adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', ...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>002203f0-1c57-4400-abc1-b783c4085743</td>\n",
       "      <td>real clinical 1 5 t magnetization prepared rap...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00243b98-f868-45e4-9b83-0c346c7ecad5</td>\n",
       "      <td>the investigators used data from the early chi...</td>\n",
       "      <td>['early childhood longitudinal study']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', ...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00243b98-f868-45e4-9b83-0c346c7ecad5</td>\n",
       "      <td>existing estimates of these children s risk e ...</td>\n",
       "      <td>['national assessment of educational progress']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00243b98-f868-45e4-9b83-0c346c7ecad5</td>\n",
       "      <td>moreover and by controlling for both sociodemo...</td>\n",
       "      <td>['early childhood longitudinal study']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00248da3-ac1d-48fa-a95e-cc88553f9583</td>\n",
       "      <td>our participants included 1196 men who perform...</td>\n",
       "      <td>['baltimore longitudinal study of aging']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00248da3-ac1d-48fa-a95e-cc88553f9583</td>\n",
       "      <td>our participants consisted of 1196 male partic...</td>\n",
       "      <td>['baltimore longitudinal study of aging blsa '...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0026563b-d5b3-417d-bd25-7656b97a044f</td>\n",
       "      <td>during the biomass study the tide was coming i...</td>\n",
       "      <td>['noaa tide gauge']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>002b53ee-5b30-497f-a2fd-56885563918c</td>\n",
       "      <td>the participants originated in 10 cohort studi...</td>\n",
       "      <td>['baltimore longitudinal study of aging']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>002cbf56-5158-4ec7-83fd-51fa7829bb13</td>\n",
       "      <td>showed an increase in ree with the number of c...</td>\n",
       "      <td>['baltimore longitudinal study of aging blsa '...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>002fdc24-9ee2-42b5-b051-373faca90c4e</td>\n",
       "      <td>for evaluation an age correction model was app...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>002fdc24-9ee2-42b5-b051-373faca90c4e</td>\n",
       "      <td>the two datasets used in this study were as fo...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>002fdc24-9ee2-42b5-b051-373faca90c4e</td>\n",
       "      <td>the 131 male and 131 female healthy subjects a...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>002fdc24-9ee2-42b5-b051-373faca90c4e</td>\n",
       "      <td>furthermore the 25 male and 25 female ad subje...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>002fdc24-9ee2-42b5-b051-373faca90c4e</td>\n",
       "      <td>for images downloaded from the adni database d...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', ...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>002fdc24-9ee2-42b5-b051-373faca90c4e</td>\n",
       "      <td>briefly pet images from the adni database were...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', ...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>002fdc24-9ee2-42b5-b051-373faca90c4e</td>\n",
       "      <td>all the results in table 5 are the average of ...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>002fdc24-9ee2-42b5-b051-373faca90c4e</td>\n",
       "      <td>iv in the fourth test to verify whether the ag...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>002fdc24-9ee2-42b5-b051-373faca90c4e</td>\n",
       "      <td>the value declined from 1 706 08 to 1 740 10 a...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>002fdc24-9ee2-42b5-b051-373faca90c4e</td>\n",
       "      <td>fourth in the present study we used the same t...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>002fdc24-9ee2-42b5-b051-373faca90c4e</td>\n",
       "      <td>thus geographical differences between the two ...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>002fdc24-9ee2-42b5-b051-373faca90c4e</td>\n",
       "      <td>the alzheimer s disease neuroimaging initiativ...</td>\n",
       "      <td>['adni', 'adni', 'alzheimer s disease neuroima...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>002fdc24-9ee2-42b5-b051-373faca90c4e</td>\n",
       "      <td>as such the investigators within the adni cont...</td>\n",
       "      <td>['adni', 'adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0030f840-8505-49c0-9991-da0d4c6c9496</td>\n",
       "      <td>19 20 21 fbmc has been designated as the mc me...</td>\n",
       "      <td>['adni', 'adni', 'adni', 'adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0030f840-8505-49c0-9991-da0d4c6c9496</td>\n",
       "      <td>12 briefly the 20 minutes of raw pet data were...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0035a1ba-6d1e-487b-bc3d-d49c5d64a3e9</td>\n",
       "      <td>the baseline images are selected from the balt...</td>\n",
       "      <td>['baltimore longitudinal study of aging blsa '...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>003822e7-b394-4d05-a32b-7c55ae9dd2e8</td>\n",
       "      <td>to further investigate the temporal consistent...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>003822e7-b394-4d05-a32b-7c55ae9dd2e8</td>\n",
       "      <td>from the full adni dataset a subset of 60 age ...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0041a4e4-6144-4780-a2a2-787222417a01</td>\n",
       "      <td>2008 the noaa optimum interpolation sea surfac...</td>\n",
       "      <td>['optimum interpolation sea surface temperatur...</td>\n",
       "      <td>['O', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'B', ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8</td>\n",
       "      <td>in section 2 we introduce the nih alzheimer s ...</td>\n",
       "      <td>['adni', 'alzheimer s disease neuroimaging ini...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8</td>\n",
       "      <td>section 5 illustrates an application of glrr i...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8</td>\n",
       "      <td>consider imaging genetic data from n independe...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8</td>\n",
       "      <td>we simulated i n d 0 and used two types of cov...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8</td>\n",
       "      <td>we chose actual snps from the adni data set</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8</td>\n",
       "      <td>for n 1 000 case 500 subjects were randomly ch...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8</td>\n",
       "      <td>the upper left panel of figure 4 presents the ...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8</td>\n",
       "      <td>the development of glrr is motivated by the an...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8</td>\n",
       "      <td>data used in the preparation of this article w...</td>\n",
       "      <td>['adni', 'adni', 'alzheimer s disease neuroima...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8</td>\n",
       "      <td>the adni was launched in 2003 by the national ...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8</td>\n",
       "      <td>the primary goal of adni has been to test whet...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', ...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8</td>\n",
       "      <td>adni is the result of efforts of many coinvest...</td>\n",
       "      <td>['adni']</td>\n",
       "      <td>['B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8</td>\n",
       "      <td>the initial goal of adni was to recruit 800 su...</td>\n",
       "      <td>['adni', 'adni', 'adni', 'adni']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "0   0007f880-0a9b-492d-9a58-76eb0b0e0bd7   \n",
       "1   0008656f-0ba2-4632-8602-3017b44c2e90   \n",
       "2   000e04d6-d6ef-442f-b070-4309493221ba   \n",
       "3   000e04d6-d6ef-442f-b070-4309493221ba   \n",
       "4   000e04d6-d6ef-442f-b070-4309493221ba   \n",
       "5   000e04d6-d6ef-442f-b070-4309493221ba   \n",
       "6   000efc17-13d8-433d-8f62-a3932fe4f3b8   \n",
       "7   000efc17-13d8-433d-8f62-a3932fe4f3b8   \n",
       "8   000efc17-13d8-433d-8f62-a3932fe4f3b8   \n",
       "9   000efc17-13d8-433d-8f62-a3932fe4f3b8   \n",
       "10  000efc17-13d8-433d-8f62-a3932fe4f3b8   \n",
       "11  000efc17-13d8-433d-8f62-a3932fe4f3b8   \n",
       "12  000efc17-13d8-433d-8f62-a3932fe4f3b8   \n",
       "13  000efc17-13d8-433d-8f62-a3932fe4f3b8   \n",
       "14  000efc17-13d8-433d-8f62-a3932fe4f3b8   \n",
       "15  000efc17-13d8-433d-8f62-a3932fe4f3b8   \n",
       "16  0010357a-6365-4e5f-b982-582e6d32c3ee   \n",
       "17  002203f0-1c57-4400-abc1-b783c4085743   \n",
       "18  002203f0-1c57-4400-abc1-b783c4085743   \n",
       "19  002203f0-1c57-4400-abc1-b783c4085743   \n",
       "20  00243b98-f868-45e4-9b83-0c346c7ecad5   \n",
       "21  00243b98-f868-45e4-9b83-0c346c7ecad5   \n",
       "22  00243b98-f868-45e4-9b83-0c346c7ecad5   \n",
       "23  00248da3-ac1d-48fa-a95e-cc88553f9583   \n",
       "24  00248da3-ac1d-48fa-a95e-cc88553f9583   \n",
       "25  0026563b-d5b3-417d-bd25-7656b97a044f   \n",
       "26  002b53ee-5b30-497f-a2fd-56885563918c   \n",
       "27  002cbf56-5158-4ec7-83fd-51fa7829bb13   \n",
       "28  002fdc24-9ee2-42b5-b051-373faca90c4e   \n",
       "29  002fdc24-9ee2-42b5-b051-373faca90c4e   \n",
       "30  002fdc24-9ee2-42b5-b051-373faca90c4e   \n",
       "31  002fdc24-9ee2-42b5-b051-373faca90c4e   \n",
       "32  002fdc24-9ee2-42b5-b051-373faca90c4e   \n",
       "33  002fdc24-9ee2-42b5-b051-373faca90c4e   \n",
       "34  002fdc24-9ee2-42b5-b051-373faca90c4e   \n",
       "35  002fdc24-9ee2-42b5-b051-373faca90c4e   \n",
       "36  002fdc24-9ee2-42b5-b051-373faca90c4e   \n",
       "37  002fdc24-9ee2-42b5-b051-373faca90c4e   \n",
       "38  002fdc24-9ee2-42b5-b051-373faca90c4e   \n",
       "39  002fdc24-9ee2-42b5-b051-373faca90c4e   \n",
       "40  002fdc24-9ee2-42b5-b051-373faca90c4e   \n",
       "41  0030f840-8505-49c0-9991-da0d4c6c9496   \n",
       "42  0030f840-8505-49c0-9991-da0d4c6c9496   \n",
       "43  0035a1ba-6d1e-487b-bc3d-d49c5d64a3e9   \n",
       "44  003822e7-b394-4d05-a32b-7c55ae9dd2e8   \n",
       "45  003822e7-b394-4d05-a32b-7c55ae9dd2e8   \n",
       "46  0041a4e4-6144-4780-a2a2-787222417a01   \n",
       "47  0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8   \n",
       "48  0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8   \n",
       "49  0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8   \n",
       "50  0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8   \n",
       "51  0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8   \n",
       "52  0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8   \n",
       "53  0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8   \n",
       "54  0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8   \n",
       "55  0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8   \n",
       "56  0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8   \n",
       "57  0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8   \n",
       "58  0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8   \n",
       "59  0046e50c-6d19-4f6b-a7c5-4fe935d3b6f8   \n",
       "\n",
       "                                      train_sentences  \\\n",
       "0   in fact organizations are now identifying digi...   \n",
       "1   besides not enough young people are entering s...   \n",
       "2   1 manages access to results of the agricultura...   \n",
       "3   the agricultural resources management survey a...   \n",
       "4   the resulting statistics provide the fulcrum f...   \n",
       "5   example atlas of rural and small town america ...   \n",
       "6   genetic and neuroimaging data on a sub sample ...   \n",
       "7   this study used data from the nacc and adni da...   \n",
       "8   patient recruitment neuroimaging acquisition a...   \n",
       "9   the adni data set is from a multicenter longit...   \n",
       "10  neither other scans nor snps were assessed fro...   \n",
       "11  54 neuroimaging and genetic parameters in adni...   \n",
       "12  47 55 arterial spin labeling asl images were o...   \n",
       "13  snp rs704180 in abcc9 and apoe e4 status infor...   \n",
       "14  this was performed by measuring cbf in conveni...   \n",
       "15  despite the challenges inherent to a retrospec...   \n",
       "16  the whole genome sequence of covid 19 has abou...   \n",
       "17  this work was supported in part by the natural...   \n",
       "18  as such investigators within adni contributed ...   \n",
       "19  real clinical 1 5 t magnetization prepared rap...   \n",
       "20  the investigators used data from the early chi...   \n",
       "21  existing estimates of these children s risk e ...   \n",
       "22  moreover and by controlling for both sociodemo...   \n",
       "23  our participants included 1196 men who perform...   \n",
       "24  our participants consisted of 1196 male partic...   \n",
       "25  during the biomass study the tide was coming i...   \n",
       "26  the participants originated in 10 cohort studi...   \n",
       "27  showed an increase in ree with the number of c...   \n",
       "28  for evaluation an age correction model was app...   \n",
       "29  the two datasets used in this study were as fo...   \n",
       "30  the 131 male and 131 female healthy subjects a...   \n",
       "31  furthermore the 25 male and 25 female ad subje...   \n",
       "32  for images downloaded from the adni database d...   \n",
       "33  briefly pet images from the adni database were...   \n",
       "34  all the results in table 5 are the average of ...   \n",
       "35  iv in the fourth test to verify whether the ag...   \n",
       "36  the value declined from 1 706 08 to 1 740 10 a...   \n",
       "37  fourth in the present study we used the same t...   \n",
       "38  thus geographical differences between the two ...   \n",
       "39  the alzheimer s disease neuroimaging initiativ...   \n",
       "40  as such the investigators within the adni cont...   \n",
       "41  19 20 21 fbmc has been designated as the mc me...   \n",
       "42  12 briefly the 20 minutes of raw pet data were...   \n",
       "43  the baseline images are selected from the balt...   \n",
       "44  to further investigate the temporal consistent...   \n",
       "45  from the full adni dataset a subset of 60 age ...   \n",
       "46  2008 the noaa optimum interpolation sea surfac...   \n",
       "47  in section 2 we introduce the nih alzheimer s ...   \n",
       "48  section 5 illustrates an application of glrr i...   \n",
       "49  consider imaging genetic data from n independe...   \n",
       "50  we simulated i n d 0 and used two types of cov...   \n",
       "51        we chose actual snps from the adni data set   \n",
       "52  for n 1 000 case 500 subjects were randomly ch...   \n",
       "53  the upper left panel of figure 4 presents the ...   \n",
       "54  the development of glrr is motivated by the an...   \n",
       "55  data used in the preparation of this article w...   \n",
       "56  the adni was launched in 2003 by the national ...   \n",
       "57  the primary goal of adni has been to test whet...   \n",
       "58  adni is the result of efforts of many coinvest...   \n",
       "59  the initial goal of adni was to recruit 800 su...   \n",
       "\n",
       "                                                kword  \\\n",
       "0   ['program for the international assessment of ...   \n",
       "1   ['trends in international mathematics and scie...   \n",
       "2        ['agricultural resources management survey']   \n",
       "3        ['agricultural resources management survey']   \n",
       "4               ['farm income and wealth statistics']   \n",
       "5   ['atlas of rural and small town america', 'cou...   \n",
       "6   ['adni', 'alzheimer s disease neuroimaging ini...   \n",
       "7                                            ['adni']   \n",
       "8                                            ['adni']   \n",
       "9                                            ['adni']   \n",
       "10                                           ['adni']   \n",
       "11                                   ['adni', 'adni']   \n",
       "12                                           ['adni']   \n",
       "13                                           ['adni']   \n",
       "14                                           ['adni']   \n",
       "15                                           ['adni']   \n",
       "16                    ['genome sequence of covid 19']   \n",
       "17  ['adni', 'alzheimer s disease neuroimaging ini...   \n",
       "18                                   ['adni', 'adni']   \n",
       "19                                           ['adni']   \n",
       "20             ['early childhood longitudinal study']   \n",
       "21    ['national assessment of educational progress']   \n",
       "22             ['early childhood longitudinal study']   \n",
       "23          ['baltimore longitudinal study of aging']   \n",
       "24  ['baltimore longitudinal study of aging blsa '...   \n",
       "25                                ['noaa tide gauge']   \n",
       "26          ['baltimore longitudinal study of aging']   \n",
       "27  ['baltimore longitudinal study of aging blsa '...   \n",
       "28                                           ['adni']   \n",
       "29                                           ['adni']   \n",
       "30                                           ['adni']   \n",
       "31                                           ['adni']   \n",
       "32                                           ['adni']   \n",
       "33                                           ['adni']   \n",
       "34                                           ['adni']   \n",
       "35                                           ['adni']   \n",
       "36                                           ['adni']   \n",
       "37                                           ['adni']   \n",
       "38                                           ['adni']   \n",
       "39  ['adni', 'adni', 'alzheimer s disease neuroima...   \n",
       "40                                   ['adni', 'adni']   \n",
       "41                   ['adni', 'adni', 'adni', 'adni']   \n",
       "42                                           ['adni']   \n",
       "43  ['baltimore longitudinal study of aging blsa '...   \n",
       "44                                           ['adni']   \n",
       "45                                           ['adni']   \n",
       "46  ['optimum interpolation sea surface temperatur...   \n",
       "47  ['adni', 'alzheimer s disease neuroimaging ini...   \n",
       "48                                           ['adni']   \n",
       "49                                           ['adni']   \n",
       "50                                           ['adni']   \n",
       "51                                           ['adni']   \n",
       "52                                           ['adni']   \n",
       "53                                           ['adni']   \n",
       "54                                           ['adni']   \n",
       "55  ['adni', 'adni', 'alzheimer s disease neuroima...   \n",
       "56                                           ['adni']   \n",
       "57                                           ['adni']   \n",
       "58                                           ['adni']   \n",
       "59                   ['adni', 'adni', 'adni', 'adni']   \n",
       "\n",
       "                                                label  sent_len  \n",
       "0   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        45  \n",
       "1   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        94  \n",
       "2   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', ...        26  \n",
       "3   ['O', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', ...        29  \n",
       "4   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        19  \n",
       "5   ['O', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'O', ...        37  \n",
       "6   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        26  \n",
       "7   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        11  \n",
       "8   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        30  \n",
       "9   ['O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', ...        35  \n",
       "10  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...         9  \n",
       "11  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', ...        28  \n",
       "12  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        13  \n",
       "13  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        33  \n",
       "14  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        29  \n",
       "15  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        29  \n",
       "16  ['O', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'O', ...        16  \n",
       "17  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        36  \n",
       "18  ['O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', ...        28  \n",
       "19  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        75  \n",
       "20  ['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', ...        41  \n",
       "21  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        38  \n",
       "22  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        68  \n",
       "23  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        37  \n",
       "24  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        33  \n",
       "25  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        48  \n",
       "26  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        92  \n",
       "27  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        27  \n",
       "28  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        39  \n",
       "29  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        48  \n",
       "30  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        18  \n",
       "31  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        21  \n",
       "32  ['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', ...        28  \n",
       "33  ['O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', ...        38  \n",
       "34  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        55  \n",
       "35  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        26  \n",
       "36  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        70  \n",
       "37  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        26  \n",
       "38  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        22  \n",
       "39  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        29  \n",
       "40  ['O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', ...        19  \n",
       "41  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        38  \n",
       "42  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        55  \n",
       "43  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', ...        16  \n",
       "44  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        26  \n",
       "45  ['O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', ...        21  \n",
       "46  ['O', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'B', ...        14  \n",
       "47  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', ...        14  \n",
       "48  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        19  \n",
       "49  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        10  \n",
       "50  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        32  \n",
       "51  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', ...         9  \n",
       "52  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        29  \n",
       "53  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        58  \n",
       "54  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        18  \n",
       "55  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        23  \n",
       "56  ['O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', ...        43  \n",
       "57  ['O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', ...        45  \n",
       "58  ['B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', ...        34  \n",
       "59  ['O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', ...        21  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df = pd.DataFrame({'id':train_Id_list, \n",
    "                          'train_sentences': train_sentences, \n",
    "                          'kword': train_keywords, \n",
    "                          'label':train_labels})\n",
    "unique_df.label = unique_df.label.astype('str')\n",
    "unique_df.kword = unique_df.kword.astype('str')\n",
    "unique_df['sent_len'] = unique_df.train_sentences.apply(lambda x : len(x.split(\" \")))\n",
    "print(unique_df.shape)\n",
    "unique_df.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the interim dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df.to_csv(\"../unique_train_df_5_len_128_cleaned_extra_labels_Albert.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
