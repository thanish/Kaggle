{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize \n",
    "from transformers import BertTokenizer, AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'Azure'\n",
    "model_name = 'model_azure_roberta_base_cleaned_xtra_label.bin'\n",
    "\n",
    "\n",
    "if platform == 'Azure':\n",
    "    bert_path = '/home/thanish/transformer_models/bert_large_uncased'\n",
    "    test_path = '../test/*'\n",
    "    model_path = '../output/'\n",
    "elif platform == 'Kaggle':\n",
    "    bert_path = '../input/bertlargeuncasedpytorch'\n",
    "    test_path = '/kaggle/input/coleridgeinitiative-show-us-the-data/test/*'\n",
    "    model_path = '../input/coleridgemodels/'\n",
    "else:\n",
    "    bert_path = 'C:/Users/thanisb/Documents/transformer_models/bert_large_uncased/'\n",
    "    test_path = '../test/*'\n",
    "    model_path = '../output/'\n",
    "    \n",
    "config = {'MAX_LEN':128,\n",
    "          'tokenizer': AutoTokenizer.from_pretrained('roberta-base' , do_lower_case=True),\n",
    "          'batch_size':16,\n",
    "          'Epoch': 3,\n",
    "          'test_path':test_path, \n",
    "          'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "          'model_path':model_path,\n",
    "          'model_name':model_name\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_joining(data_dict_id):\n",
    "    '''\n",
    "    This function is to join all the text data from different sections in the json to a single\n",
    "    text file. \n",
    "    '''\n",
    "    data_length = len(data_dict_id)\n",
    "\n",
    "    temp = [data_dict_id[i]['text'] for i in range(data_length)]\n",
    "    temp = '. '.join(temp)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>train_sentences</th>\n",
       "      <th>kword</th>\n",
       "      <th>label</th>\n",
       "      <th>sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007f880-0a9b-492d-9a58-76eb0b0e0bd7</td>\n",
       "      <td>in fact organizations are now identifying digi...</td>\n",
       "      <td>['program for the international assessment of ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008656f-0ba2-4632-8602-3017b44c2e90</td>\n",
       "      <td>besides not enough young people are entering s...</td>\n",
       "      <td>['trends in international mathematics and scie...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n",
       "      <td>1 manages access to results of the agricultura...</td>\n",
       "      <td>['agricultural resources management survey']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n",
       "      <td>the agricultural resources management survey a...</td>\n",
       "      <td>['agricultural resources management survey']</td>\n",
       "      <td>['O', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n",
       "      <td>the resulting statistics provide the fulcrum f...</td>\n",
       "      <td>['farm income and wealth statistics']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58226</th>\n",
       "      <td>ffd19b3c-f941-45e5-9382-934b5041ec96</td>\n",
       "      <td>pesticide use was estimated by using statewide...</td>\n",
       "      <td>['census of agriculture']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58227</th>\n",
       "      <td>ffe7f334-245a-4de7-b600-d7ff4e28bfca</td>\n",
       "      <td>interestingly the genome sequences of sars cov...</td>\n",
       "      <td>['genome sequences of sars cov 2']</td>\n",
       "      <td>['O', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'B', ...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58228</th>\n",
       "      <td>ffeb3568-7aed-4dbe-b177-cbd7f46f34af</td>\n",
       "      <td>as part of the program for international stude...</td>\n",
       "      <td>['trends in international mathematics and scie...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58229</th>\n",
       "      <td>ffee2676-a778-4521-b947-e1e420b126c5</td>\n",
       "      <td>analysis considered first time beginning posts...</td>\n",
       "      <td>['beginning postsecondary students']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'O', ...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58230</th>\n",
       "      <td>ffee2676-a778-4521-b947-e1e420b126c5</td>\n",
       "      <td>my prior research illustrated with use of begi...</td>\n",
       "      <td>['beginning postsecondary student']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', ...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58231 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0      0007f880-0a9b-492d-9a58-76eb0b0e0bd7   \n",
       "1      0008656f-0ba2-4632-8602-3017b44c2e90   \n",
       "2      000e04d6-d6ef-442f-b070-4309493221ba   \n",
       "3      000e04d6-d6ef-442f-b070-4309493221ba   \n",
       "4      000e04d6-d6ef-442f-b070-4309493221ba   \n",
       "...                                     ...   \n",
       "58226  ffd19b3c-f941-45e5-9382-934b5041ec96   \n",
       "58227  ffe7f334-245a-4de7-b600-d7ff4e28bfca   \n",
       "58228  ffeb3568-7aed-4dbe-b177-cbd7f46f34af   \n",
       "58229  ffee2676-a778-4521-b947-e1e420b126c5   \n",
       "58230  ffee2676-a778-4521-b947-e1e420b126c5   \n",
       "\n",
       "                                         train_sentences  \\\n",
       "0      in fact organizations are now identifying digi...   \n",
       "1      besides not enough young people are entering s...   \n",
       "2      1 manages access to results of the agricultura...   \n",
       "3      the agricultural resources management survey a...   \n",
       "4      the resulting statistics provide the fulcrum f...   \n",
       "...                                                  ...   \n",
       "58226  pesticide use was estimated by using statewide...   \n",
       "58227  interestingly the genome sequences of sars cov...   \n",
       "58228  as part of the program for international stude...   \n",
       "58229  analysis considered first time beginning posts...   \n",
       "58230  my prior research illustrated with use of begi...   \n",
       "\n",
       "                                                   kword  \\\n",
       "0      ['program for the international assessment of ...   \n",
       "1      ['trends in international mathematics and scie...   \n",
       "2           ['agricultural resources management survey']   \n",
       "3           ['agricultural resources management survey']   \n",
       "4                  ['farm income and wealth statistics']   \n",
       "...                                                  ...   \n",
       "58226                          ['census of agriculture']   \n",
       "58227                 ['genome sequences of sars cov 2']   \n",
       "58228  ['trends in international mathematics and scie...   \n",
       "58229               ['beginning postsecondary students']   \n",
       "58230                ['beginning postsecondary student']   \n",
       "\n",
       "                                                   label  sent_len  \n",
       "0      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        45  \n",
       "1      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        94  \n",
       "2      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', ...        26  \n",
       "3      ['O', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', ...        29  \n",
       "4      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        19  \n",
       "...                                                  ...       ...  \n",
       "58226  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        28  \n",
       "58227  ['O', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'B', ...        38  \n",
       "58228  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        66  \n",
       "58229  ['O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'O', ...        37  \n",
       "58230  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', ...       105  \n",
       "\n",
       "[58231 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df = pd.read_csv(\"../labelled_data/unique_train_df_5_len_128_cleaned_extra_labels_Roberta.csv\")\n",
    "unique_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping all the sentences less than 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>train_sentences</th>\n",
       "      <th>kword</th>\n",
       "      <th>label</th>\n",
       "      <th>sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007f880-0a9b-492d-9a58-76eb0b0e0bd7</td>\n",
       "      <td>in fact organizations are now identifying digi...</td>\n",
       "      <td>['program for the international assessment of ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008656f-0ba2-4632-8602-3017b44c2e90</td>\n",
       "      <td>besides not enough young people are entering s...</td>\n",
       "      <td>['trends in international mathematics and scie...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n",
       "      <td>1 manages access to results of the agricultura...</td>\n",
       "      <td>['agricultural resources management survey']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n",
       "      <td>the agricultural resources management survey a...</td>\n",
       "      <td>['agricultural resources management survey']</td>\n",
       "      <td>['O', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e04d6-d6ef-442f-b070-4309493221ba</td>\n",
       "      <td>the resulting statistics provide the fulcrum f...</td>\n",
       "      <td>['farm income and wealth statistics']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58226</th>\n",
       "      <td>ffd19b3c-f941-45e5-9382-934b5041ec96</td>\n",
       "      <td>pesticide use was estimated by using statewide...</td>\n",
       "      <td>['census of agriculture']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58227</th>\n",
       "      <td>ffe7f334-245a-4de7-b600-d7ff4e28bfca</td>\n",
       "      <td>interestingly the genome sequences of sars cov...</td>\n",
       "      <td>['genome sequences of sars cov 2']</td>\n",
       "      <td>['O', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'B', ...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58228</th>\n",
       "      <td>ffeb3568-7aed-4dbe-b177-cbd7f46f34af</td>\n",
       "      <td>as part of the program for international stude...</td>\n",
       "      <td>['trends in international mathematics and scie...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58229</th>\n",
       "      <td>ffee2676-a778-4521-b947-e1e420b126c5</td>\n",
       "      <td>analysis considered first time beginning posts...</td>\n",
       "      <td>['beginning postsecondary students']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'O', ...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58230</th>\n",
       "      <td>ffee2676-a778-4521-b947-e1e420b126c5</td>\n",
       "      <td>my prior research illustrated with use of begi...</td>\n",
       "      <td>['beginning postsecondary student']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', ...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58231 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0      0007f880-0a9b-492d-9a58-76eb0b0e0bd7   \n",
       "1      0008656f-0ba2-4632-8602-3017b44c2e90   \n",
       "2      000e04d6-d6ef-442f-b070-4309493221ba   \n",
       "3      000e04d6-d6ef-442f-b070-4309493221ba   \n",
       "4      000e04d6-d6ef-442f-b070-4309493221ba   \n",
       "...                                     ...   \n",
       "58226  ffd19b3c-f941-45e5-9382-934b5041ec96   \n",
       "58227  ffe7f334-245a-4de7-b600-d7ff4e28bfca   \n",
       "58228  ffeb3568-7aed-4dbe-b177-cbd7f46f34af   \n",
       "58229  ffee2676-a778-4521-b947-e1e420b126c5   \n",
       "58230  ffee2676-a778-4521-b947-e1e420b126c5   \n",
       "\n",
       "                                         train_sentences  \\\n",
       "0      in fact organizations are now identifying digi...   \n",
       "1      besides not enough young people are entering s...   \n",
       "2      1 manages access to results of the agricultura...   \n",
       "3      the agricultural resources management survey a...   \n",
       "4      the resulting statistics provide the fulcrum f...   \n",
       "...                                                  ...   \n",
       "58226  pesticide use was estimated by using statewide...   \n",
       "58227  interestingly the genome sequences of sars cov...   \n",
       "58228  as part of the program for international stude...   \n",
       "58229  analysis considered first time beginning posts...   \n",
       "58230  my prior research illustrated with use of begi...   \n",
       "\n",
       "                                                   kword  \\\n",
       "0      ['program for the international assessment of ...   \n",
       "1      ['trends in international mathematics and scie...   \n",
       "2           ['agricultural resources management survey']   \n",
       "3           ['agricultural resources management survey']   \n",
       "4                  ['farm income and wealth statistics']   \n",
       "...                                                  ...   \n",
       "58226                          ['census of agriculture']   \n",
       "58227                 ['genome sequences of sars cov 2']   \n",
       "58228  ['trends in international mathematics and scie...   \n",
       "58229               ['beginning postsecondary students']   \n",
       "58230                ['beginning postsecondary student']   \n",
       "\n",
       "                                                   label  sent_len  \n",
       "0      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        45  \n",
       "1      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        94  \n",
       "2      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', ...        26  \n",
       "3      ['O', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', ...        29  \n",
       "4      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        19  \n",
       "...                                                  ...       ...  \n",
       "58226  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        28  \n",
       "58227  ['O', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'B', ...        38  \n",
       "58228  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        66  \n",
       "58229  ['O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'O', ...        37  \n",
       "58230  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', ...       105  \n",
       "\n",
       "[58231 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df = unique_df.loc[unique_df.sent_len<512, :].reset_index(drop=True)\n",
    "unique_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take unqiue of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56550, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df = unique_df.drop_duplicates()\n",
    "unique_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking the sample of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56550, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique_df = unique_df.sample(int(unique_df.shape[0]*0.5)).reset_index(drop=True)\n",
    "unique_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53722, 5) (2828, 5)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "train_df, valid_df = train_test_split(unique_df, test_size=0.05)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "\n",
    "print(train_df.shape, valid_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the DataFrame back to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_2_idx = {'O': 0 , 'B': 1, 'P': 2}\n",
    "\n",
    "def dataset_2_list(df):\n",
    "    id_list = df.id.values.tolist()\n",
    "    sentences_list = df.train_sentences.values.tolist()\n",
    "    keywords_list = df.kword.apply(lambda x : eval(x)).values.tolist()\n",
    "    \n",
    "    labels_list = df.label.apply(lambda x : eval(x)).values.tolist()    \n",
    "    labels_list = [list(map(tags_2_idx.get, lab)) for lab in labels_list]\n",
    "    \n",
    "    return id_list, sentences_list, keywords_list, labels_list\n",
    "\n",
    "final_train_id_list, final_train_sentences, final_train_keywords, final_train_labels = dataset_2_list(df=unique_df)\n",
    "final_valid_id_list, final_valid_sentences, final_valid_keywords, final_valid_labels = dataset_2_list(df=valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # verification\n",
    "# ind = 650\n",
    "# final_train_sentences[ind], config['tokenizer'].tokenize(final_train_sentences[ind]), final_train_keywords[ind], final_train_labels[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forming the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class form_input():\n",
    "    def __init__(self, ID, sentence, kword, label, data_type='test'):\n",
    "        self.id = ID\n",
    "        self.sentence = sentence\n",
    "        self.kword = kword\n",
    "        self.label = label\n",
    "        self.max_length = config['MAX_LEN']\n",
    "        self.tokenizer = config['tokenizer']\n",
    "        self.data_type = data_type\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentence)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        toks = config['tokenizer'].tokenize(\" \"+self.sentence[item])\n",
    "        label = self.label[item]\n",
    "\n",
    "        if len(toks)>self.max_length:\n",
    "            toks = toks[:self.max_length]\n",
    "            label = label[:self.max_length]\n",
    "        \n",
    "        \n",
    "        ########################################\n",
    "        # Forming the inputs\n",
    "        ids = config['tokenizer'].convert_tokens_to_ids(toks)\n",
    "        tok_type_id = [0] * len(ids)\n",
    "        att_mask = [1] * len(ids)\n",
    "        \n",
    "        # Padding\n",
    "        pad_len = self.max_length - len(ids)        \n",
    "        ids = ids + [2] * pad_len\n",
    "        tok_type_id = tok_type_id + [0] * pad_len\n",
    "        att_mask = att_mask + [0] * pad_len\n",
    "        \n",
    "        ########################################            \n",
    "        # Forming the label\n",
    "        if self.data_type !='test':\n",
    "            label = label + [2]*pad_len\n",
    "        else:\n",
    "            label = 1\n",
    "        \n",
    "        ########################################\n",
    "        \n",
    "#         print(f'After---, {len(ids)}, {len(tok_type_id)}, {len(att_mask)}, {len(label)}')\n",
    "        \n",
    "        return {'pub_id': self.id[item],\n",
    "                #'item': item,\n",
    "                #'sentence': self.sentence[item],\n",
    "                #'kword' : self.kword[item],\n",
    "                'ids': torch.tensor(ids, dtype = torch.long),\n",
    "                'tok_type_id': torch.tensor(tok_type_id, dtype = torch.long),\n",
    "                'att_mask': torch.tensor(att_mask, dtype = torch.long),\n",
    "                'target': torch.tensor(label, dtype = torch.long)\n",
    "               }\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod_input = form_input(ID=final_train_id_list, \n",
    "                              sentence=final_train_sentences, \n",
    "                              kword=final_train_keywords, \n",
    "                              label=final_train_labels, \n",
    "                              data_type='train')\n",
    "\n",
    "valid_prod_input = form_input(ID=final_valid_id_list, \n",
    "                              sentence=final_valid_sentences, \n",
    "                              kword=final_valid_keywords, \n",
    "                              label=final_valid_labels, \n",
    "                              data_type='valid')\n",
    "\n",
    "train_prod_input_data_loader = DataLoader(train_prod_input, \n",
    "                                          batch_size= config['batch_size'], \n",
    "                                          shuffle=True)\n",
    "\n",
    "valid_prod_input_data_loader = DataLoader(valid_prod_input, \n",
    "                                          batch_size= config['batch_size'], \n",
    "                                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ind = 8443\n",
    "# train_prod_input[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting_seed(seed_no=100):\n",
    "    random.seed(seed_no)\n",
    "    np.random.seed(seed_no)\n",
    "    torch.manual_seed(seed_no)\n",
    "    torch.cuda.manual_seed_all(seed_no)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    actual_flat = labels.flatten()\n",
    "    pred_flat = preds.flatten()\n",
    "    \n",
    "    # Get all non-padded index\n",
    "    non_padded_index = np.where(actual_flat != tags_2_idx[\"P\"])[0]\n",
    "    \n",
    "    # Only non-padded positions for the actual and the predicted\n",
    "    actual_flat = actual_flat[non_padded_index]\n",
    "    pred_flat = pred_flat[non_padded_index]\n",
    "    \n",
    "    print(confusion_matrix(actual_flat, pred_flat))\n",
    "    \n",
    "    # Accuracy\n",
    "    Accuracy = np.sum(actual_flat == pred_flat ) / len(pred_flat )\n",
    "    \n",
    "    # Recall calculator\n",
    "    condition = (actual_flat == 1)\n",
    "    actual_index = np.where(condition)[0]\n",
    "    actual_flat_rec = actual_flat[actual_index]\n",
    "    pred_flat_rec = pred_flat[actual_index]\n",
    "    Recall = np.sum(actual_flat_rec == pred_flat_rec) / len(pred_flat_rec)\n",
    "    \n",
    "    # Precision calculator\n",
    "    condition = (pred_flat == 1)\n",
    "    pred_index = np.where(condition)[0]\n",
    "    actual_flat_prc = actual_flat[pred_index]\n",
    "    pred_flat_prc = pred_flat[pred_index]\n",
    "    Precision = np.sum(actual_flat_prc == pred_flat_prc) / len(pred_flat_prc)\n",
    "\n",
    "    # Jaccard similarity\n",
    "    common_index = np.intersect1d(actual_index, pred_index)\n",
    "    jaccard_similarity = float(len(common_index))/( len(actual_index) + len(pred_index) - len(common_index))\n",
    "    \n",
    "    return Accuracy, Recall, Precision, jaccard_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, optimizer):\n",
    "    \n",
    "    setting_seed(seed_no=100)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for index, dataset in enumerate(tqdm(data_loader, total = len(data_loader))):\n",
    "        batch_input_ids = dataset['ids'].to(config['device'], dtype = torch.long)\n",
    "        batch_att_mask = dataset['att_mask'].to(config['device'], dtype = torch.long)\n",
    "        batch_tok_type_id = dataset['tok_type_id'].to(config['device'], dtype = torch.long)\n",
    "        batch_target = dataset['target'].to(config['device'], dtype = torch.long)\n",
    "                \n",
    "        model.zero_grad()\n",
    "        output = model(batch_input_ids, \n",
    "                       token_type_ids=None,\n",
    "                       attention_mask=batch_att_mask,\n",
    "                       labels=batch_target)\n",
    "        \n",
    "        step_loss = output[0]\n",
    "        prediction = output[1]\n",
    "        \n",
    "        step_loss.sum().backward()\n",
    "        optimizer.step()        \n",
    "        train_loss += step_loss\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    tr_loss = train_loss.sum()/len(data_loader)\n",
    "    \n",
    "    return tr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(data_loader, model):\n",
    "    \n",
    "    setting_seed(seed_no=100)\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss = 0\n",
    "    predictions = np.array([], dtype = np.int64).reshape(0, config['MAX_LEN'])\n",
    "    true_labels = np.array([], dtype = np.int64).reshape(0, config['MAX_LEN'])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for index, dataset in enumerate(tqdm(data_loader, total = len(data_loader))):\n",
    "            batch_input_ids = dataset['ids'].to(config['device'], dtype = torch.long)\n",
    "            batch_att_mask = dataset['att_mask'].to(config['device'], dtype = torch.long)\n",
    "            batch_tok_type_id = dataset['tok_type_id'].to(config['device'], dtype = torch.long)\n",
    "            batch_target = dataset['target'].to(config['device'], dtype = torch.long)\n",
    "\n",
    "            output = model(batch_input_ids, \n",
    "                           token_type_ids=None,\n",
    "                           attention_mask=batch_att_mask,\n",
    "                           labels=batch_target)\n",
    "\n",
    "            step_loss = output[0]\n",
    "            eval_prediction = output[1]\n",
    "\n",
    "            eval_loss += step_loss\n",
    "            \n",
    "            eval_prediction = np.argmax(eval_prediction.detach().to('cpu').numpy(), axis = 2)\n",
    "            actual = batch_target.to('cpu').numpy()\n",
    "            \n",
    "            predictions = np.concatenate((predictions, eval_prediction), axis = 0)\n",
    "            true_labels = np.concatenate((true_labels, actual), axis = 0)\n",
    "           \n",
    "        ev_loss = eval_loss.sum()/len(data_loader)\n",
    "        Accuracy, Recall, Precision, jaccard_similarity = flat_accuracy(preds=predictions , labels=true_labels)\n",
    "        \n",
    "        print(f'Eval Accuracy: {Accuracy}, Recall: {Recall}, Precision: {Precision}, jaccard_similarity: {jaccard_similarity}')\n",
    "            \n",
    "    return ev_loss, Precision, predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_engine(epoch, train_data, valid_data):\n",
    "    setting_seed(seed_no=100)\n",
    "    model = transformers.RobertaForTokenClassification.from_pretrained('roberta-base',  num_labels = len(tags_2_idx))\n",
    "    model = nn.DataParallel(model)\n",
    "    model = model.to(config['device'])\n",
    "    \n",
    "    params = model.parameters()\n",
    "    optimizer = torch.optim.Adam(params, lr= 3e-5)\n",
    "    \n",
    "    best_eval_loss = 1000000\n",
    "    best_Precision = 0\n",
    "    for i in range(epoch):\n",
    "        train_loss = train_fn(data_loader = train_data, \n",
    "                              model=model, \n",
    "                              optimizer=optimizer)\n",
    "        eval_loss, Precision, eval_predictions, true_labels = eval_fn(data_loader = valid_data, \n",
    "                                                                      model=model)\n",
    "        \n",
    "        print(f\"Epoch {i} , Train loss: {train_loss}, Eval loss: {eval_loss}\")\n",
    "\n",
    "#         if Precision > best_Precision:\n",
    "#             best_Precision = Precision           \n",
    "        \n",
    "        saving_name = config['model_path'] + f\"epoch_{i}_\" + config['model_name']\n",
    "        print(\"Saving the model:\", saving_name)\n",
    "        torch.save(model.state_dict(), saving_name)\n",
    "            \n",
    "    return model, eval_predictions, true_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3535/3535 [37:11<00:00,  1.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 177/177 [00:39<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107238     82]\n",
      " [   127  11404]]\n",
      "Eval Accuracy: 0.9982414956542225, Recall: 0.9889862110831671, Precision: 0.9928608741076093, jaccard_similarity: 0.9820029277533798\n",
      "Epoch 0 , Train loss: 0.03866076096892357, Eval loss: 0.011711147613823414\n",
      "Saving the model: ../output/epoch_0_model_azure_roberta_base_cleaned_xtra_label.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3535/3535 [37:14<00:00,  1.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 177/177 [00:40<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107248     72]\n",
      " [    69  11462]]\n",
      "Eval Accuracy: 0.9988136406088295, Recall: 0.994016130431012, Precision: 0.9937575862666898, jaccard_similarity: 0.987847970352495\n",
      "Epoch 1 , Train loss: 0.010807993821799755, Eval loss: 0.01004213560372591\n",
      "Saving the model: ../output/epoch_1_model_azure_roberta_base_cleaned_xtra_label.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3535/3535 [37:18<00:00,  1.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 177/177 [00:39<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107248     72]\n",
      " [    85  11446]]\n",
      "Eval Accuracy: 0.998679018266569, Recall: 0.9926285664729859, Precision: 0.9937489147421428, jaccard_similarity: 0.9864690166336292\n",
      "Epoch 2 , Train loss: 0.007933207787573338, Eval loss: 0.008990558795630932\n",
      "Saving the model: ../output/epoch_2_model_azure_roberta_base_cleaned_xtra_label.bin\n"
     ]
    }
   ],
   "source": [
    "model, eval_predictions, eval_true_labels = train_engine(epoch=config['Epoch'], \n",
    "                                                         train_data=train_prod_input_data_loader, \n",
    "                                                         valid_data=valid_prod_input_data_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
